{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('southparklines/All-seasons.csv')\n",
    "questions = []\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, data.shape[0] - 1):\n",
    "    if data.iloc[i + 1][2] == 'Stan':\n",
    "        questions.append(data.iloc[i][3])\n",
    "        answers.append(data.iloc[i + 1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Going away? For how long?\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forever.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"  \",\"\",text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "\n",
    "    text = text.strip()\n",
    "    text = '<start> ' + text + ' <end>'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> going away for how long <end>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> forever <end>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_questions = []\n",
    "clean_answers = []\n",
    "\n",
    "for q in questions:\n",
    "    clean_questions.append(preprocess_sentence(q))\n",
    "for a in answers:\n",
    "    clean_answers.append(preprocess_sentence(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "min_length = 1\n",
    "short_questions_temp = []\n",
    "short_answers_temp = []\n",
    "\n",
    "i = 0\n",
    "for question in clean_questions:\n",
    "    if len(question.split()) >= min_length and len(question.split()) <= max_length:\n",
    "        short_questions_temp.append(question)\n",
    "        short_answers_temp.append(clean_answers[i])\n",
    "    i += 1\n",
    "\n",
    "# Filter out the answers that are too short/long\n",
    "shorted_q = []\n",
    "shorted_a = []\n",
    "\n",
    "i = 0\n",
    "for answer in short_answers_temp:\n",
    "    if len(answer.split()) >= min_length and len(answer.split()) <= max_length:\n",
    "        shorted_a.append(answer)\n",
    "        shorted_q.append(short_questions_temp[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "def load_dataset(inp_lang, targ_lang):\n",
    "  # creating cleaned input, output pairs\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6806"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shorted_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(inp_lang, targ_lang):\n",
    "  # creating cleaned input, output pairs\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(shorted_q, shorted_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6806, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6806, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5444 5444 1362 1362\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print(\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "9 ----> that\n",
      "5 ----> is\n",
      "488 ----> true\n",
      "114 ----> huh\n",
      "119 ----> man\n",
      "9 ----> that\n",
      "364 ----> makes\n",
      "34 ----> me\n",
      "79 ----> really\n",
      "5966 ----> reflect\n",
      "24 ----> on\n",
      "25 ----> my\n",
      "948 ----> pet\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "11 ----> that\n",
      "5 ----> is\n",
      "342 ----> such\n",
      "14 ----> a\n",
      "201 ----> great\n",
      "745 ----> paper\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 30]), TensorShape([64, 30]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 30, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4755)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './nmt_with_attention_southpark/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "          \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start save checkpoint in Epoch:  0\n",
      "Epoch 1 Batch 0 Loss 2.2005\n",
      "Start save checkpoint in Epoch:  0\n",
      "Epoch 1 Loss 1.8569\n",
      "Time taken for 1 epoch 46.637102365493774 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  1\n",
      "Epoch 2 Batch 0 Loss 1.7103\n",
      "Epoch 2 Loss 1.6074\n",
      "Time taken for 1 epoch 14.074546813964844 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  2\n",
      "Epoch 3 Batch 0 Loss 1.4485\n",
      "Epoch 3 Loss 1.4899\n",
      "Time taken for 1 epoch 14.546295166015625 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  3\n",
      "Epoch 4 Batch 0 Loss 1.4257\n",
      "Epoch 4 Loss 1.4203\n",
      "Time taken for 1 epoch 14.370802164077759 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  4\n",
      "Epoch 5 Batch 0 Loss 1.2157\n",
      "Epoch 5 Loss 1.3639\n",
      "Time taken for 1 epoch 13.999103307723999 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  5\n",
      "Epoch 6 Batch 0 Loss 1.2384\n",
      "Epoch 6 Loss 1.3110\n",
      "Time taken for 1 epoch 13.992437839508057 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  6\n",
      "Epoch 7 Batch 0 Loss 1.2188\n",
      "Epoch 7 Loss 1.2605\n",
      "Time taken for 1 epoch 13.981332063674927 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  7\n",
      "Epoch 8 Batch 0 Loss 1.2034\n",
      "Epoch 8 Loss 1.2146\n",
      "Time taken for 1 epoch 13.980982303619385 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  8\n",
      "Epoch 9 Batch 0 Loss 1.3153\n",
      "Epoch 9 Loss 1.1668\n",
      "Time taken for 1 epoch 13.958436250686646 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  9\n",
      "Epoch 10 Batch 0 Loss 0.9020\n",
      "Epoch 10 Loss 1.1183\n",
      "Time taken for 1 epoch 14.255054235458374 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  10\n",
      "Epoch 11 Batch 0 Loss 1.1751\n",
      "Start save checkpoint in Epoch:  10\n",
      "Epoch 11 Loss 1.0680\n",
      "Time taken for 1 epoch 14.596936225891113 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  11\n",
      "Epoch 12 Batch 0 Loss 1.0443\n",
      "Epoch 12 Loss 1.0157\n",
      "Time taken for 1 epoch 14.069546461105347 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  12\n",
      "Epoch 13 Batch 0 Loss 1.0412\n",
      "Epoch 13 Loss 0.9594\n",
      "Time taken for 1 epoch 14.023370742797852 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  13\n",
      "Epoch 14 Batch 0 Loss 0.7773\n",
      "Epoch 14 Loss 0.9044\n",
      "Time taken for 1 epoch 14.017574787139893 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  14\n",
      "Epoch 15 Batch 0 Loss 0.6762\n",
      "Epoch 15 Loss 0.8445\n",
      "Time taken for 1 epoch 13.969164609909058 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  15\n",
      "Epoch 16 Batch 0 Loss 0.8672\n",
      "Epoch 16 Loss 0.7828\n",
      "Time taken for 1 epoch 14.040394067764282 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  16\n",
      "Epoch 17 Batch 0 Loss 0.6976\n",
      "Epoch 17 Loss 0.7148\n",
      "Time taken for 1 epoch 14.023802280426025 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  17\n",
      "Epoch 18 Batch 0 Loss 0.5788\n",
      "Epoch 18 Loss 0.6466\n",
      "Time taken for 1 epoch 14.016594409942627 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  18\n",
      "Epoch 19 Batch 0 Loss 0.5861\n",
      "Epoch 19 Loss 0.5785\n",
      "Time taken for 1 epoch 14.023503541946411 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  19\n",
      "Epoch 20 Batch 0 Loss 0.5490\n",
      "Epoch 20 Loss 0.5080\n",
      "Time taken for 1 epoch 14.030409574508667 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  20\n",
      "Epoch 21 Batch 0 Loss 0.4446\n",
      "Start save checkpoint in Epoch:  20\n",
      "Epoch 21 Loss 0.4382\n",
      "Time taken for 1 epoch 14.614364385604858 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  21\n",
      "Epoch 22 Batch 0 Loss 0.3778\n",
      "Epoch 22 Loss 0.3743\n",
      "Time taken for 1 epoch 14.029608964920044 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  22\n",
      "Epoch 23 Batch 0 Loss 0.2986\n",
      "Epoch 23 Loss 0.3127\n",
      "Time taken for 1 epoch 14.05216383934021 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  23\n",
      "Epoch 24 Batch 0 Loss 0.1838\n",
      "Epoch 24 Loss 0.2559\n",
      "Time taken for 1 epoch 14.002644300460815 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  24\n",
      "Epoch 25 Batch 0 Loss 0.1979\n",
      "Epoch 25 Loss 0.2056\n",
      "Time taken for 1 epoch 13.991927146911621 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  25\n",
      "Epoch 26 Batch 0 Loss 0.1730\n",
      "Epoch 26 Loss 0.1656\n",
      "Time taken for 1 epoch 14.021063089370728 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  26\n",
      "Epoch 27 Batch 0 Loss 0.1057\n",
      "Epoch 27 Loss 0.1344\n",
      "Time taken for 1 epoch 14.04235315322876 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  27\n",
      "Epoch 28 Batch 0 Loss 0.0991\n",
      "Epoch 28 Loss 0.1090\n",
      "Time taken for 1 epoch 14.032136678695679 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  28\n",
      "Epoch 29 Batch 0 Loss 0.0773\n",
      "Epoch 29 Loss 0.0875\n",
      "Time taken for 1 epoch 13.997923135757446 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  29\n",
      "Epoch 30 Batch 0 Loss 0.0742\n",
      "Epoch 30 Loss 0.0721\n",
      "Time taken for 1 epoch 14.023375749588013 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  30\n",
      "Epoch 31 Batch 0 Loss 0.0539\n",
      "Start save checkpoint in Epoch:  30\n",
      "Epoch 31 Loss 0.0611\n",
      "Time taken for 1 epoch 14.584357738494873 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  31\n",
      "Epoch 32 Batch 0 Loss 0.0411\n",
      "Epoch 32 Loss 0.0526\n",
      "Time taken for 1 epoch 14.023963212966919 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  32\n",
      "Epoch 33 Batch 0 Loss 0.0485\n",
      "Epoch 33 Loss 0.0467\n",
      "Time taken for 1 epoch 14.015586853027344 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  33\n",
      "Epoch 34 Batch 0 Loss 0.0356\n",
      "Epoch 34 Loss 0.0420\n",
      "Time taken for 1 epoch 14.067510843276978 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  34\n",
      "Epoch 35 Batch 0 Loss 0.0441\n",
      "Epoch 35 Loss 0.0388\n",
      "Time taken for 1 epoch 14.024287700653076 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  35\n",
      "Epoch 36 Batch 0 Loss 0.0352\n",
      "Epoch 36 Loss 0.0367\n",
      "Time taken for 1 epoch 14.05380654335022 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  36\n",
      "Epoch 37 Batch 0 Loss 0.0350\n",
      "Epoch 37 Loss 0.0364\n",
      "Time taken for 1 epoch 14.049201965332031 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  37\n",
      "Epoch 38 Batch 0 Loss 0.0336\n",
      "Epoch 38 Loss 0.0350\n",
      "Time taken for 1 epoch 14.028609037399292 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  38\n",
      "Epoch 39 Batch 0 Loss 0.0245\n",
      "Epoch 39 Loss 0.0335\n",
      "Time taken for 1 epoch 14.030867099761963 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  39\n",
      "Epoch 40 Batch 0 Loss 0.0169\n",
      "Epoch 40 Loss 0.0328\n",
      "Time taken for 1 epoch 14.05301284790039 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  40\n",
      "Epoch 41 Batch 0 Loss 0.0289\n",
      "Start save checkpoint in Epoch:  40\n",
      "Epoch 41 Loss 0.0318\n",
      "Time taken for 1 epoch 14.668144464492798 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  41\n",
      "Epoch 42 Batch 0 Loss 0.0386\n",
      "Epoch 42 Loss 0.0325\n",
      "Time taken for 1 epoch 14.00825834274292 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  42\n",
      "Epoch 43 Batch 0 Loss 0.0472\n",
      "Epoch 43 Loss 0.0322\n",
      "Time taken for 1 epoch 14.022554636001587 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  43\n",
      "Epoch 44 Batch 0 Loss 0.0413\n",
      "Epoch 44 Loss 0.0320\n",
      "Time taken for 1 epoch 14.008416175842285 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  44\n",
      "Epoch 45 Batch 0 Loss 0.0736\n",
      "Epoch 45 Loss 0.0323\n",
      "Time taken for 1 epoch 13.986192464828491 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  45\n",
      "Epoch 46 Batch 0 Loss 0.0270\n",
      "Epoch 46 Loss 0.0329\n",
      "Time taken for 1 epoch 14.027771472930908 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  46\n",
      "Epoch 47 Batch 0 Loss 0.0311\n",
      "Epoch 47 Loss 0.0395\n",
      "Time taken for 1 epoch 13.981166124343872 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  47\n",
      "Epoch 48 Batch 0 Loss 0.0245\n",
      "Epoch 48 Loss 0.0438\n",
      "Time taken for 1 epoch 14.047790765762329 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  48\n",
      "Epoch 49 Batch 0 Loss 0.0358\n",
      "Epoch 49 Loss 0.0453\n",
      "Time taken for 1 epoch 14.037563562393188 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  49\n",
      "Epoch 50 Batch 0 Loss 0.0367\n",
      "Epoch 50 Loss 0.0429\n",
      "Time taken for 1 epoch 14.019188165664673 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  50\n",
      "Epoch 51 Batch 0 Loss 0.0350\n",
      "Start save checkpoint in Epoch:  50\n",
      "Epoch 51 Loss 0.0410\n",
      "Time taken for 1 epoch 14.609342575073242 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  51\n",
      "Epoch 52 Batch 0 Loss 0.0499\n",
      "Epoch 52 Loss 0.0382\n",
      "Time taken for 1 epoch 14.02521538734436 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  52\n",
      "Epoch 53 Batch 0 Loss 0.0240\n",
      "Epoch 53 Loss 0.0313\n",
      "Time taken for 1 epoch 14.028833389282227 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  53\n",
      "Epoch 54 Batch 0 Loss 0.0151\n",
      "Epoch 54 Loss 0.0258\n",
      "Time taken for 1 epoch 14.022788763046265 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  54\n",
      "Epoch 55 Batch 0 Loss 0.0107\n",
      "Epoch 55 Loss 0.0239\n",
      "Time taken for 1 epoch 14.137349605560303 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  55\n",
      "Epoch 56 Batch 0 Loss 0.0116\n",
      "Epoch 56 Loss 0.0221\n",
      "Time taken for 1 epoch 13.980119943618774 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  56\n",
      "Epoch 57 Batch 0 Loss 0.0107\n",
      "Epoch 57 Loss 0.0202\n",
      "Time taken for 1 epoch 13.94950795173645 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  57\n",
      "Epoch 58 Batch 0 Loss 0.0108\n",
      "Epoch 58 Loss 0.0193\n",
      "Time taken for 1 epoch 13.932368993759155 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  58\n",
      "Epoch 59 Batch 0 Loss 0.0216\n",
      "Epoch 59 Loss 0.0193\n",
      "Time taken for 1 epoch 13.934770345687866 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  59\n",
      "Epoch 60 Batch 0 Loss 0.0202\n",
      "Epoch 60 Loss 0.0178\n",
      "Time taken for 1 epoch 13.95016360282898 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  60\n",
      "Epoch 61 Batch 0 Loss 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start save checkpoint in Epoch:  60\n",
      "Epoch 61 Loss 0.0175\n",
      "Time taken for 1 epoch 14.542177200317383 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  61\n",
      "Epoch 62 Batch 0 Loss 0.0114\n",
      "Epoch 62 Loss 0.0168\n",
      "Time taken for 1 epoch 13.974360942840576 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  62\n",
      "Epoch 63 Batch 0 Loss 0.0130\n",
      "Epoch 63 Loss 0.0166\n",
      "Time taken for 1 epoch 13.978537321090698 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  63\n",
      "Epoch 64 Batch 0 Loss 0.0210\n",
      "Epoch 64 Loss 0.0163\n",
      "Time taken for 1 epoch 13.90520977973938 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  64\n",
      "Epoch 65 Batch 0 Loss 0.0133\n",
      "Epoch 65 Loss 0.0163\n",
      "Time taken for 1 epoch 13.965195894241333 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  65\n",
      "Epoch 66 Batch 0 Loss 0.0065\n",
      "Epoch 66 Loss 0.0171\n",
      "Time taken for 1 epoch 13.910097122192383 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  66\n",
      "Epoch 67 Batch 0 Loss 0.0085\n",
      "Epoch 67 Loss 0.0166\n",
      "Time taken for 1 epoch 13.923608303070068 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  67\n",
      "Epoch 68 Batch 0 Loss 0.0199\n",
      "Epoch 68 Loss 0.0168\n",
      "Time taken for 1 epoch 13.93539547920227 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  68\n",
      "Epoch 69 Batch 0 Loss 0.0147\n",
      "Epoch 69 Loss 0.0171\n",
      "Time taken for 1 epoch 13.925556421279907 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  69\n",
      "Epoch 70 Batch 0 Loss 0.0154\n",
      "Epoch 70 Loss 0.0183\n",
      "Time taken for 1 epoch 13.942397594451904 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  70\n",
      "Epoch 71 Batch 0 Loss 0.0229\n",
      "Start save checkpoint in Epoch:  70\n",
      "Epoch 71 Loss 0.0184\n",
      "Time taken for 1 epoch 14.529748678207397 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  71\n",
      "Epoch 72 Batch 0 Loss 0.0123\n",
      "Epoch 72 Loss 0.0203\n",
      "Time taken for 1 epoch 13.970206022262573 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  72\n",
      "Epoch 73 Batch 0 Loss 0.0036\n",
      "Epoch 73 Loss 0.0219\n",
      "Time taken for 1 epoch 13.907186031341553 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  73\n",
      "Epoch 74 Batch 0 Loss 0.0145\n",
      "Epoch 74 Loss 0.0302\n",
      "Time taken for 1 epoch 13.925147533416748 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  74\n",
      "Epoch 75 Batch 0 Loss 0.0580\n",
      "Epoch 75 Loss 0.0557\n",
      "Time taken for 1 epoch 13.897088527679443 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  75\n",
      "Epoch 76 Batch 0 Loss 0.0592\n",
      "Epoch 76 Loss 0.0912\n",
      "Time taken for 1 epoch 13.94349718093872 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  76\n",
      "Epoch 77 Batch 0 Loss 0.0513\n",
      "Epoch 77 Loss 0.0845\n",
      "Time taken for 1 epoch 13.929057359695435 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  77\n",
      "Epoch 78 Batch 0 Loss 0.0475\n",
      "Epoch 78 Loss 0.0556\n",
      "Time taken for 1 epoch 13.942894220352173 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  78\n",
      "Epoch 79 Batch 0 Loss 0.0256\n",
      "Epoch 79 Loss 0.0362\n",
      "Time taken for 1 epoch 13.945071697235107 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  79\n",
      "Epoch 80 Batch 0 Loss 0.0281\n",
      "Epoch 80 Loss 0.0272\n",
      "Time taken for 1 epoch 13.954456329345703 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  80\n",
      "Epoch 81 Batch 0 Loss 0.0312\n",
      "Start save checkpoint in Epoch:  80\n",
      "Epoch 81 Loss 0.0209\n",
      "Time taken for 1 epoch 14.528282880783081 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  81\n",
      "Epoch 82 Batch 0 Loss 0.0137\n",
      "Epoch 82 Loss 0.0184\n",
      "Time taken for 1 epoch 13.984414339065552 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  82\n",
      "Epoch 83 Batch 0 Loss 0.0167\n",
      "Epoch 83 Loss 0.0168\n",
      "Time taken for 1 epoch 13.959360599517822 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  83\n",
      "Epoch 84 Batch 0 Loss 0.0135\n",
      "Epoch 84 Loss 0.0155\n",
      "Time taken for 1 epoch 13.916703462600708 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  84\n",
      "Epoch 85 Batch 0 Loss 0.0194\n",
      "Epoch 85 Loss 0.0146\n",
      "Time taken for 1 epoch 13.945422649383545 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  85\n",
      "Epoch 86 Batch 0 Loss 0.0222\n",
      "Epoch 86 Loss 0.0141\n",
      "Time taken for 1 epoch 13.955111026763916 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  86\n",
      "Epoch 87 Batch 0 Loss 0.0120\n",
      "Epoch 87 Loss 0.0145\n",
      "Time taken for 1 epoch 13.91867971420288 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  87\n",
      "Epoch 88 Batch 0 Loss 0.0094\n",
      "Epoch 88 Loss 0.0141\n",
      "Time taken for 1 epoch 13.904814720153809 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  88\n",
      "Epoch 89 Batch 0 Loss 0.0120\n",
      "Epoch 89 Loss 0.0139\n",
      "Time taken for 1 epoch 13.924084901809692 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  89\n",
      "Epoch 90 Batch 0 Loss 0.0104\n",
      "Epoch 90 Loss 0.0131\n",
      "Time taken for 1 epoch 13.931390762329102 sec\n",
      "\n",
      "Start save checkpoint in Epoch:  90\n",
      "Epoch 91 Batch 0 Loss 0.0079\n",
      "Start save checkpoint in Epoch:  90\n",
      "Epoch 91 Loss 0.0131\n",
      "Time taken for 1 epoch 14.533958911895752 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 91\n",
    "loss_plt = []\n",
    "for epoch in range(EPOCHS):\n",
    "  \n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(\"Start save checkpoint in Epoch: \", epoch)\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if epoch%10 == 0:\n",
    "        print(\"Start save checkpoint in Epoch: \", epoch)\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    avloss = float(total_loss/steps_per_epoch)\n",
    "    loss_plt.append(avloss)\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, _ = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    return result[:-7]\n",
    "  #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  #plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hi stan <end>\n",
      "Predicted translation: you said we were going to be raggedy ann and andy remember <end> \n"
     ]
    }
   ],
   "source": [
    "results = translate(\"Hi Stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you said we were going to be raggedy ann and andy remember'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "print(max_length_targ, max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hi stan <end>\n",
      "Predicted translation: you said we were going to be raggedy ann and andy remember <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"Hi Stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> going way <end>\n",
      "Predicted translation: yeah let s go <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"Going Way\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> what are you doing here <end>\n",
      "Predicted translation: please ih ih it will not take long <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"What are you doing here?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i was the vice president <end>\n",
      "Predicted translation: i know <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"i was the vice president\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i do not get it <end>\n",
      "Predicted translation: me neither <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"i do not get it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> stan <end>\n",
      "Predicted translation: all right they finally came for us <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> it just does not seem right <end>\n",
      "Predicted translation: yeah our eyes are finally open dude it is like waking up for the first time <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"it just does not seem right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> guys can i talk to you <end>\n",
      "Predicted translation: sure dude <end> \n"
     ]
    }
   ],
   "source": [
    "translate(\"guys can i talk to you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(EPOCHS),loss_plt)\n",
    "plt.title(\"Change in loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Lost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Hello!',\n",
    "'How are you?',\n",
    "'What’s your name?',\n",
    "'When were you born?',\n",
    "'Where are you from?',\n",
    "'Are you a man or a woman?',\n",
    "'Why are you here?',\n",
    "'Okay bye!',\n",
    "'See you later.',\n",
    "'Happy birthday!',\n",
    "'Have a nice day!',\n",
    "'How old are you?',\n",
    "'Would you like some tea?',\n",
    "'What a nice day today!',\n",
    "'How do you do?',\n",
    "'Hey.',\n",
    "'What’s up?',\n",
    "'Good morning.',\n",
    "'How are you doing?',\n",
    "'Nice to meet you.',\n",
    "'Thank you.',\n",
    "'Where are you going?',\n",
    "'Good luck!',\n",
    "'Sounds good?',\n",
    "'Talk to you later.',\n",
    "'How can i help you?',\n",
    "'I do not feel very well.',\n",
    "'I miss you.',\n",
    "'What are you going to do?',\n",
    "'I do not understand.',\n",
    "'Who is Bill clinton?',\n",
    "'Is the sky blue or black?',\n",
    "'Does a cat have a ear?',\n",
    "'Can a cat fly?',\n",
    "'How many legs does a cat have?',\n",
    "'How many legs does a spider have?',\n",
    "'What is the color of the sky?',\n",
    "'What is the color of water?',\n",
    "'How much is two plus two?',\n",
    "'How much is ten add two?',\n",
    "'What do you like to talk about?',\n",
    "'What is your job?',\n",
    "'Tell me something about you.',\n",
    "'What do you think about coffee?\\xa0',\n",
    "'Do you like math?',\n",
    "'Can you tell me a joke?',\n",
    "'I really like the song. What do you think?',\n",
    "'Do you like basketball?',\n",
    "'What kind of music do you like best?',\n",
    "'What’s your favorite sport?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not feel very well.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Input: <start> hello <end>\n",
      "Predicted translation: help <end> \n",
      "1\n",
      "Input: <start> how are you <end>\n",
      "Predicted translation: i do not know i have to talk to the world then we have to talk to the world then we have to talk to the world then we have \n",
      "2\n",
      "Input: <start> what s your name <end>\n",
      "Predicted translation: you have to do <end> \n",
      "3\n",
      "Input: <start> when were you born <end>\n",
      "Predicted translation: dude you are here you know you you know you you know you you know you you know you you know you you know you you know you you know \n",
      "4\n",
      "Input: <start> where are you from <end>\n",
      "Predicted translation: we have to be that <end> \n",
      "5\n",
      "Input: <start> are you a man or a woman <end>\n",
      "Predicted translation: you meanyou <end> \n",
      "6\n",
      "Input: <start> why are you here <end>\n",
      "Predicted translation: i am done with you <end> \n",
      "7\n",
      "Input: <start> okay bye <end>\n",
      "Predicted translation: hello <end> \n",
      "8\n",
      "Input: <start> see you later <end>\n",
      "Predicted translation: wow this is this <end> \n",
      "9\n",
      "Input: <start> happy birthday <end>\n",
      "Predicted translation: dude you have a big good <end> \n",
      "10\n",
      "Input: <start> have a nice day <end>\n",
      "Predicted translation: dude come on dude <end> \n",
      "11\n",
      "Input: <start> how old are you <end>\n",
      "Predicted translation: why does that is not gonna say that is not gonna say that is not gonna say that is not gonna say that is not gonna say that is not \n",
      "12\n",
      "Input: <start> would you like some tea <end>\n",
      "Predicted translation: that is it <end> \n",
      "13\n",
      "Input: <start> what a nice day today <end>\n",
      "Predicted translation: come on guys we are gonna get in the last update we get in the video store now <end> \n",
      "14\n",
      "Input: <start> how do you do <end>\n",
      "Predicted translation: cause i have a reading out a merry christmas <end> \n",
      "15\n",
      "Input: <start> hey <end>\n",
      "Predicted translation: hey kid over herehey uh listen you know this whole singing and dancing thing you do i think you need to uh ease off a little bit <end> \n",
      "16\n",
      "Input: <start> what s up <end>\n",
      "Predicted translation: oh god <end> \n",
      "17\n",
      "Input: <start> good morning <end>\n",
      "Predicted translation: wow <end> \n",
      "18\n",
      "Input: <start> how are you doing <end>\n",
      "Predicted translation: uh we are not being a dick we are supposed to feed them to put a dick we are supposed to feed them to put a dick we are supposed \n",
      "19\n",
      "Input: <start> nice to meet you <end>\n",
      "Predicted translation: aw mr mackey <end> \n",
      "20\n",
      "Input: <start> thank you <end>\n",
      "Predicted translation: mr garrison stop <end> \n",
      "21\n",
      "Input: <start> where are you going <end>\n",
      "Predicted translation: i am going home <end> \n",
      "22\n",
      "Input: <start> good luck <end>\n",
      "Predicted translation: let s go <end> \n",
      "23\n",
      "Input: <start> sounds good <end>\n",
      "Predicted translation: hey hey my god <end> \n",
      "24\n",
      "Input: <start> talk to you later <end>\n",
      "Predicted translation: i am sick <end> \n",
      "25\n",
      "Input: <start> how can i help you <end>\n",
      "Predicted translation: well it is my friend kyle i think he is really really sick <end> \n",
      "26\n",
      "Input: <start> i do not feel very well <end>\n",
      "Predicted translation: look like it <end> \n",
      "27\n",
      "Input: <start> i miss you <end>\n",
      "Predicted translation: i am gonna be here <end> \n",
      "28\n",
      "Input: <start> what are you going to do <end>\n",
      "Predicted translation: please ih it you have to go <end> \n",
      "29\n",
      "Input: <start> i do not understand <end>\n",
      "Predicted translation: do you do not get in a fight <end> \n",
      "30\n",
      "Input: <start> who is bill clinton <end>\n",
      "Predicted translation: no dude look dude look dude look dude look dude look dude look dude look dude look dude look dude look dude look dude look dude look dude look dude \n",
      "31\n",
      "Input: <start> is the sky blue or black <end>\n",
      "Predicted translation: holy fucking christ <end> \n",
      "32\n",
      "Input: <start> does a cat have a ear <end>\n",
      "Predicted translation: oh dude kenny you really want you <end> \n",
      "33\n",
      "Input: <start> can a cat fly <end>\n",
      "Predicted translation: huh <end> \n",
      "34\n",
      "Input: <start> how many legs does a cat have <end>\n",
      "Predicted translation: uh we were <end> \n",
      "35\n",
      "Input: <start> how many legs does a spider have <end>\n",
      "Predicted translation: uh we were only out <end> \n",
      "36\n",
      "Input: <start> what is the color of the sky <end>\n",
      "Predicted translation: well i guess we are not getting goodi <end> \n",
      "37\n",
      "Input: <start> what is the color of water <end>\n",
      "Predicted translation: well i do not really have to get on <end> \n",
      "38\n",
      "Input: <start> how much is two plus two <end>\n",
      "Predicted translation: no you are not gonna have to talk to you <end> \n",
      "39\n",
      "Input: <start> how much is ten add two <end>\n",
      "Predicted translation: let s got a big douche <end> \n",
      "40\n",
      "Input: <start> what do you like to talk about <end>\n",
      "Predicted translation: i do not think so <end> \n",
      "41\n",
      "Input: <start> what is your job <end>\n",
      "Predicted translation: i do not know <end> \n",
      "42\n",
      "Input: <start> tell me something about you <end>\n",
      "Predicted translation: having five billion people on <end> \n",
      "43\n",
      "Input: <start> what do you think about coffee <end>\n",
      "Predicted translation: i do not know anything <end> \n",
      "44\n",
      "Input: <start> do you like math <end>\n",
      "Predicted translation: no i am sure glad that is because of it <end> \n",
      "45\n",
      "Input: <start> can you tell me a joke <end>\n",
      "Predicted translation: hello <end> \n",
      "46\n",
      "Input: <start> i really like the song what do you think <end>\n",
      "Predicted translation: dude i thought the hell did you say anything <end> \n",
      "47\n",
      "Input: <start> do you like basketball <end>\n",
      "Predicted translation: do not know what we just came down in america <end> \n",
      "48\n",
      "Input: <start> what kind of music do you like best <end>\n",
      "Predicted translation: i am just a show of it <end> \n",
      "49\n",
      "Input: <start> what s your favorite sport <end>\n",
      "Predicted translation: detective why <end> \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for q in questions:\n",
    "    print(i)\n",
    "    answers.append(translate(q))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'questions': questions, 'answers': answers}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"south_park_results.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
